# ü§ñ CLUES‚Ñ¢ LLM-First Data Collection Architecture

**Philosophy:** Let AI do ALL the heavy lifting - scraping, parsing, enriching, validating
**Your Assets:** Claude Max API, GPT Pro API, Grok Pro API
**Target:** Florida properties with 100% AI-powered data extraction

---

## üéØ WHY LLM-FIRST IS SUPERIOR

### **Traditional Scraping Problems:**
‚ùå Breaks when websites change layout
‚ùå Requires custom code per site
‚ùå Can't handle dynamic JavaScript
‚ùå No intelligence in data extraction
‚ùå Requires maintenance for each site
‚ùå Legal gray area with aggressive scraping

### **LLM-First Advantages:**
‚úÖ **Universal Extractor** - Works on ANY website
‚úÖ **Self-Healing** - Adapts to layout changes automatically
‚úÖ **Intelligent Parsing** - Understands context
‚úÖ **Multi-Modal** - Can read text, images, PDFs
‚úÖ **Data Enrichment** - Fills missing fields intelligently
‚úÖ **Natural Language Queries** - "Get all properties under $500k in Miami with good schools"
‚úÖ **Quality Control** - Validates and corrects data
‚úÖ **Legal Compliance** - Uses official APIs where available

---

## üèóÔ∏è ARCHITECTURE: Triple-LLM Orchestration

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    LLM DATA PIPELINE ARCHITECTURE                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

USER REQUEST
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ORCHESTRATOR (Your Node.js)     ‚îÇ
‚îÇ   - Receives scraping request    ‚îÇ
‚îÇ   - Routes to best LLM           ‚îÇ
‚îÇ   - Manages rate limits          ‚îÇ
‚îÇ   - Deduplicates data            ‚îÇ
‚îÇ   - Stores in IndexedDB          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚ñº                 ‚ñº                 ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CLAUDE  ‚îÇ      ‚îÇ   GPT   ‚îÇ      ‚îÇ  GROK   ‚îÇ      ‚îÇ HYBRID  ‚îÇ
‚îÇ  MAX    ‚îÇ      ‚îÇ   PRO   ‚îÇ      ‚îÇ   PRO   ‚îÇ      ‚îÇ  MODE   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ                 ‚îÇ                 ‚îÇ                 ‚îÇ
    ‚îÇ                 ‚îÇ                 ‚îÇ                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    TASK DISTRIBUTION                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ CLAUDE:                                                       ‚îÇ
‚îÇ ‚úì Primary scraper (best at structured extraction)            ‚îÇ
‚îÇ ‚úì Complex multi-page workflows                               ‚îÇ
‚îÇ ‚úì Computer Use tool for interactive sites                    ‚îÇ
‚îÇ ‚úì PDF/document parsing                                       ‚îÇ
‚îÇ ‚úì Data validation & cleaning                                 ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ GPT:                                                          ‚îÇ
‚îÇ ‚úì Web browsing for real-time data                           ‚îÇ
‚îÇ ‚úì Image analysis (property photos)                           ‚îÇ
‚îÇ ‚úì Natural language data enrichment                           ‚îÇ
‚îÇ ‚úì Market trend analysis                                      ‚îÇ
‚îÇ ‚úì Backup when Claude rate-limited                           ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ GROK:                                                         ‚îÇ
‚îÇ ‚úì Real-time web search (best for current data)              ‚îÇ
‚îÇ ‚úì Social media scraping (Twitter/X integration)             ‚îÇ
‚îÇ ‚úì News & market sentiment                                    ‚îÇ
‚îÇ ‚úì Backup for both Claude & GPT                              ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ HYBRID:                                                       ‚îÇ
‚îÇ ‚úì Cross-validate data from all 3 LLMs                       ‚îÇ
‚îÇ ‚úì Consensus-based accuracy (majority vote)                  ‚îÇ
‚îÇ ‚úì Fill missing fields from multiple sources                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   INDEXED DB (CLUES_Quantum_DB)         ‚îÇ
‚îÇ   - 7 object stores                     ‚îÇ
‚îÇ   - 100+ property variables             ‚îÇ
‚îÇ   - Full property history               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üíª IMPLEMENTATION: Unified LLM Scraper

### **File: `src/scrapers/llm-unified-scraper.js`**

```javascript
/**
 * CLUES‚Ñ¢ LLM-First Data Scraper
 * Uses Claude Max, GPT Pro, Grok Pro for 100% AI-powered data extraction
 *
 * @version 2.0.0 - LLM-First Architecture
 */

import Anthropic from '@anthropic-ai/sdk';
import OpenAI from 'openai';
import { Grok } from 'grok-api'; // Hypothetical - adjust based on actual Grok API

class UnifiedLLMScraper {
    constructor() {
        // Initialize all 3 LLM clients
        this.claude = new Anthropic({
            apiKey: process.env.ANTHROPIC_API_KEY // Your Claude Max API key
        });

        this.gpt = new OpenAI({
            apiKey: process.env.OPENAI_API_KEY // Your GPT Pro API key
        });

        this.grok = new Grok({
            apiKey: process.env.GROK_API_KEY // Your Grok Pro API key
        });

        // Rate limit tracking
        this.claudeCount = 0;
        this.gptCount = 0;
        this.grokCount = 0;

        // Cost tracking
        this.totalCost = 0;

        this.dataManager = new DataManager();
    }

    /**
     * MASTER SCRAPING METHOD
     * Intelligently routes to best LLM based on task
     */
    async scrapeProperty(url, preferredLLM = 'auto') {
        console.log(`ü§ñ Scraping property: ${url}`);

        try {
            let result;

            // Auto-select best LLM
            if (preferredLLM === 'auto') {
                preferredLLM = this.selectBestLLM(url);
            }

            // Route to appropriate LLM
            switch (preferredLLM) {
                case 'claude':
                    result = await this.scrapeWithClaude(url);
                    break;
                case 'gpt':
                    result = await this.scrapeWithGPT(url);
                    break;
                case 'grok':
                    result = await this.scrapeWithGrok(url);
                    break;
                case 'hybrid':
                    result = await this.scrapeWithHybrid(url);
                    break;
                default:
                    throw new Error(`Unknown LLM: ${preferredLLM}`);
            }

            // Validate and enrich
            const enrichedProperty = await this.enrichProperty(result);

            // Save to IndexedDB
            await this.dataManager.addProperty(enrichedProperty);

            console.log(`‚úÖ Successfully scraped: ${enrichedProperty.address.street}`);
            return enrichedProperty;

        } catch (error) {
            console.error(`‚ùå Failed to scrape ${url}:`, error);
            throw error;
        }
    }

    /**
     * CLAUDE SCRAPER
     * Best for: Structured extraction, complex workflows
     */
    async scrapeWithClaude(url) {
        console.log(`üîµ Using Claude Max for ${url}`);

        const prompt = `
You are a real estate data extraction specialist. Visit this property listing and extract ALL available information:

URL: ${url}

Extract the following data and return as valid JSON:

{
    "address": {
        "street": "full street address",
        "city": "city name",
        "state": "FL",
        "zip": "ZIP code",
        "county": "county name"
    },
    "price": {
        "current": 450000,
        "original": 465000,
        "price_per_sqft": 225
    },
    "bedrooms": 3,
    "bathrooms": {
        "total": 2.5,
        "full": 2,
        "half": 1
    },
    "square_feet": {
        "living": 2000,
        "lot": 5000
    },
    "year_built": 1995,
    "property_type": "single_family",
    "mls_number": "MLS12345",
    "status": "active",
    "days_on_market": 15,
    "garage_spaces": 2,
    "stories": 2,
    "features": {
        "interior": ["hardwood floors", "granite countertops"],
        "exterior": ["pool", "deck"],
        "appliances": ["stainless steel"]
    },
    "description": "full property description",
    "photos": ["photo_url_1", "photo_url_2"],
    "virtual_tour": "3d_tour_url",

    // CRITICAL: Also extract these if available
    "hoa_fee": 250,
    "property_taxes": 5000,
    "school_ratings": {
        "elementary": "elementary school name (rating if shown)",
        "middle": "middle school name (rating if shown)",
        "high": "high school name (rating if shown)"
    },
    "walk_score": 75,
    "crime_rating": "low/medium/high if mentioned",
    "nearby_amenities": ["parks", "shopping", "restaurants"],
    "flood_zone": "X or AE or other if mentioned",
    "last_sold_date": "2020-05-15",
    "last_sold_price": 380000,
    "price_history": [
        {"date": "2024-11-01", "price": 450000, "event": "listed"},
        {"date": "2024-10-15", "price": 465000, "event": "price_reduction"}
    ]
}

IMPORTANT RULES:
1. Extract EVERY field that exists on the page
2. If a field is missing, set it to null (not undefined)
3. Convert all numbers to actual numbers (not strings)
4. Be precise with addresses (include unit numbers, directions)
5. Capture ALL photos (not just featured image)
6. Include price history if visible
7. Extract school names AND ratings if shown
8. Look for walk score, crime data, flood zone info in neighborhood sections

Return ONLY the JSON, no markdown, no explanation.
`;

        const message = await this.claude.messages.create({
            model: 'claude-sonnet-4-20250514', // Latest Claude 3.5 Sonnet
            max_tokens: 4096,
            messages: [{
                role: 'user',
                content: prompt
            }],
            tools: [{
                type: 'computer_20241022',
                name: 'computer',
                display_width_px: 1920,
                display_height_px: 1080
            }]
        });

        // Parse Claude's response
        const jsonText = this.extractJSON(message.content[0].text);
        const propertyData = JSON.parse(jsonText);

        // Track usage
        this.claudeCount++;
        this.totalCost += this.estimateCost('claude', message.usage);

        return propertyData;
    }

    /**
     * GPT SCRAPER
     * Best for: Real-time browsing, image analysis
     */
    async scrapeWithGPT(url) {
        console.log(`üü¢ Using GPT-4 Pro for ${url}`);

        const completion = await this.gpt.chat.completions.create({
            model: 'gpt-4-turbo-preview',
            messages: [{
                role: 'system',
                content: 'You are a real estate data extraction specialist. Extract property data from web pages and return as JSON.'
            }, {
                role: 'user',
                content: `
Visit this property listing URL: ${url}

Browse the page and extract ALL available property data. Return as JSON with this structure:
{
    "address": {...},
    "price": {...},
    "bedrooms": number,
    "bathrooms": {...},
    "square_feet": {...},
    ... (all fields like Claude example above)
}

CRITICAL: Also look for and extract:
- Walk Score (usually in neighborhood section)
- Crime data (may say "low crime", "safe neighborhood", etc.)
- School ratings (often near bottom or in sidebar)
- Flood risk (sometimes in disclosures)
- Nearby amenities (parks, shopping, restaurants)

Return ONLY valid JSON, no markdown.
                `
            }],
            tools: [{
                type: 'function',
                function: {
                    name: 'web_search',
                    description: 'Search the web and browse pages',
                    parameters: {
                        type: 'object',
                        properties: {
                            url: { type: 'string' }
                        }
                    }
                }
            }]
        });

        const jsonText = this.extractJSON(completion.choices[0].message.content);
        const propertyData = JSON.parse(jsonText);

        // Track usage
        this.gptCount++;
        this.totalCost += this.estimateCost('gpt', completion.usage);

        return propertyData;
    }

    /**
     * GROK SCRAPER
     * Best for: Real-time web data, X/Twitter sentiment
     */
    async scrapeWithGrok(url) {
        console.log(`‚ö° Using Grok Pro for ${url}`);

        const response = await this.grok.complete({
            model: 'grok-2-latest',
            messages: [{
                role: 'user',
                content: `
Extract ALL property data from this listing: ${url}

Return as JSON with complete property details including:
- Basic info (address, price, beds, baths, sqft)
- Features and amenities
- School information and ratings
- Walk Score if visible
- Crime data or safety mentions
- Flood zone or natural hazard info
- Photos and virtual tour links
- Price history if available

Also search X/Twitter for recent mentions of this address or neighborhood to gauge sentiment.

Return ONLY valid JSON.
                `
            }],
            tools: ['web_search', 'x_search'] // Grok has native X integration
        });

        const jsonText = this.extractJSON(response.output);
        const propertyData = JSON.parse(jsonText);

        // Track usage
        this.grokCount++;
        this.totalCost += this.estimateCost('grok', response.usage);

        return propertyData;
    }

    /**
     * HYBRID SCRAPER
     * Uses all 3 LLMs and cross-validates
     */
    async scrapeWithHybrid(url) {
        console.log(`üîÄ Using HYBRID mode (all 3 LLMs) for ${url}`);

        // Run all 3 in parallel
        const [claudeData, gptData, grokData] = await Promise.allSettled([
            this.scrapeWithClaude(url),
            this.scrapeWithGPT(url),
            this.scrapeWithGrok(url)
        ]);

        // Extract successful results
        const results = [
            claudeData.status === 'fulfilled' ? claudeData.value : null,
            gptData.status === 'fulfilled' ? gptData.value : null,
            grokData.status === 'fulfilled' ? grokData.value : null
        ].filter(r => r !== null);

        if (results.length === 0) {
            throw new Error('All LLMs failed to scrape property');
        }

        // Merge results with consensus logic
        const mergedData = this.mergeWithConsensus(results);

        console.log(`‚úÖ Hybrid scraping complete - ${results.length}/3 LLMs succeeded`);
        return mergedData;
    }

    /**
     * INTELLIGENT LLM SELECTION
     * Chooses best LLM based on URL and requirements
     */
    selectBestLLM(url) {
        // Parse URL to determine best LLM
        const domain = new URL(url).hostname;

        // Claude is best for complex, structured sites
        if (domain.includes('realtor.com') || domain.includes('redfin.com')) {
            return 'claude';
        }

        // GPT is best for image-heavy sites
        if (domain.includes('zillow.com') || domain.includes('trulia.com')) {
            return 'gpt';
        }

        // Grok is best for social/real-time data
        if (domain.includes('homes.com') || domain.includes('compass.com')) {
            return 'grok';
        }

        // Default to Claude (most reliable)
        return 'claude';
    }

    /**
     * ENRICH PROPERTY DATA
     * Uses LLMs to fill missing fields and enhance data
     */
    async enrichProperty(baseData) {
        console.log(`üîç Enriching property data...`);

        // If critical fields are missing, use LLM to infer or fetch
        const enrichmentPrompt = `
Given this property data:
${JSON.stringify(baseData, null, 2)}

Enrich it by:
1. If walk_score is missing, estimate based on address/location (use web search)
2. If school_ratings are missing, look up schools near this address
3. If crime_rating is missing, search for crime data for this ZIP code
4. If flood_zone is missing, check FEMA flood maps or mention in property description
5. If hoa_fee is missing but property_type is condo/townhouse, estimate typical HOA for area
6. Calculate estimated property_taxes if missing (use assessed value * local rate)
7. Estimate nearby_amenities based on location

Return the SAME JSON structure with enriched/filled fields. Mark any estimated fields with "_estimated": true.
`;

        // Use cheapest LLM (Grok or Claude depending on rate limits)
        const enriched = await this.scrapeWithGrok(baseData.address.full);

        return { ...baseData, ...enriched };
    }

    /**
     * MERGE RESULTS WITH CONSENSUS
     * When multiple LLMs provide data, use majority vote
     */
    mergeWithConsensus(results) {
        const merged = {};

        // Get all unique keys across all results
        const allKeys = new Set();
        results.forEach(result => {
            this.getAllKeys(result).forEach(key => allKeys.add(key));
        });

        // For each field, find consensus value
        allKeys.forEach(key => {
            const values = results.map(r => this.getNestedValue(r, key)).filter(v => v !== undefined);

            if (values.length === 0) {
                return; // Skip if no LLM provided this field
            }

            if (values.length === 1) {
                this.setNestedValue(merged, key, values[0]);
                return;
            }

            // Majority vote for numeric/string fields
            if (typeof values[0] === 'number' || typeof values[0] === 'string') {
                const mode = this.findMode(values);
                this.setNestedValue(merged, key, mode);
            } else {
                // For objects/arrays, prefer most complete version
                const mostComplete = values.reduce((a, b) =>
                    JSON.stringify(a).length > JSON.stringify(b).length ? a : b
                );
                this.setNestedValue(merged, key, mostComplete);
            }
        });

        return merged;
    }

    /**
     * BATCH SCRAPING
     * Scrape multiple properties efficiently
     */
    async scrapeMultipleProperties(urls, options = {}) {
        const {
            batchSize = 5,        // Process 5 at a time
            preferredLLM = 'auto',
            useHybrid = false     // Set true for critical data
        } = options;

        console.log(`üì¶ Batch scraping ${urls.length} properties...`);

        const results = [];
        const errors = [];

        // Process in batches to avoid rate limits
        for (let i = 0; i < urls.length; i += batchSize) {
            const batch = urls.slice(i, i + batchSize);

            console.log(`üì¶ Processing batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(urls.length / batchSize)}`);

            const batchResults = await Promise.allSettled(
                batch.map(url => this.scrapeProperty(url, useHybrid ? 'hybrid' : preferredLLM))
            );

            batchResults.forEach((result, idx) => {
                if (result.status === 'fulfilled') {
                    results.push(result.value);
                } else {
                    errors.push({
                        url: batch[idx],
                        error: result.reason
                    });
                }
            });

            // Rate limiting pause between batches
            if (i + batchSize < urls.length) {
                await this.sleep(2000); // 2 second pause
            }
        }

        console.log(`‚úÖ Batch complete: ${results.length} succeeded, ${errors.length} failed`);
        console.log(`üí∞ Total cost: $${this.totalCost.toFixed(4)}`);

        return { results, errors };
    }

    /**
     * CITY-WIDE SCRAPING
     * LLM generates list of properties, then scrapes each
     */
    async scrapeCity(city, state = 'FL', options = {}) {
        const {
            maxProperties = 100,
            minPrice = 0,
            maxPrice = Infinity,
            propertyTypes = ['single_family', 'condo', 'townhouse']
        } = options;

        console.log(`üèôÔ∏è Scraping ${city}, ${state}...`);

        // Step 1: Use LLM to find property listings
        const listingsPrompt = `
Search for ALL active real estate listings in ${city}, ${state} that match:
- Price range: $${minPrice.toLocaleString()} - $${maxPrice.toLocaleString()}
- Property types: ${propertyTypes.join(', ')}
- Maximum ${maxProperties} properties

Return a JSON array of listing URLs:
[
    "https://www.realtor.com/property/...",
    "https://www.zillow.com/homedetails/...",
    ...
]

Use Realtor.com, Zillow, Redfin, and Trulia. Return ONLY the JSON array.
`;

        // Use Grok (best for real-time web search)
        const response = await this.grok.complete({
            model: 'grok-2-latest',
            messages: [{
                role: 'user',
                content: listingsPrompt
            }],
            tools: ['web_search']
        });

        const urls = JSON.parse(this.extractJSON(response.output));
        console.log(`üìã Found ${urls.length} listings in ${city}`);

        // Step 2: Scrape all listings
        const { results, errors } = await this.scrapeMultipleProperties(urls, {
            batchSize: 5,
            preferredLLM: 'auto'
        });

        return {
            city,
            state,
            totalFound: urls.length,
            scraped: results.length,
            failed: errors.length,
            properties: results,
            errors: errors
        };
    }

    /**
     * LLM-POWERED WALK SCORE EXTRACTION
     * Let LLM find Walk Score instead of using API
     */
    async getWalkScoreViaLLM(address) {
        const prompt = `
Search the web for the Walk Score, Transit Score, and Bike Score for this address:
${address}

Visit walkscore.com or other sources and extract:
{
    "walk_score": 75,
    "transit_score": 65,
    "bike_score": 80,
    "description": "Very Walkable"
}

Return ONLY JSON.
`;

        // Use cheapest/fastest LLM
        const response = await this.grok.complete({
            model: 'grok-2-latest',
            messages: [{ role: 'user', content: prompt }],
            tools: ['web_search']
        });

        return JSON.parse(this.extractJSON(response.output));
    }

    /**
     * LLM-POWERED CRIME DATA EXTRACTION
     * Let LLM find crime statistics instead of scraping manually
     */
    async getCrimeDataViaLLM(address) {
        const prompt = `
Search the web for crime statistics and safety information for this address:
${address}

Check sources like:
- NeighborhoodScout.com
- SpotCrime.com
- Local police department data
- Realtor.com neighborhood info

Return:
{
    "crime_index": 25,  // 0-100 scale (lower = safer)
    "crime_rating": "low",  // low/medium/high
    "violent_crime_rate": 150,  // per 100,000 people
    "property_crime_rate": 1200,  // per 100,000 people
    "safety_score": 85,  // 0-100 (higher = safer)
    "description": "This neighborhood is safer than 75% of US neighborhoods"
}

Return ONLY JSON.
`;

        const response = await this.claude.messages.create({
            model: 'claude-sonnet-4-20250514',
            max_tokens: 2048,
            messages: [{ role: 'user', content: prompt }]
        });

        return JSON.parse(this.extractJSON(response.content[0].text));
    }

    // ===== UTILITY METHODS =====

    extractJSON(text) {
        // Remove markdown code blocks
        text = text.replace(/```json\n?/g, '').replace(/```\n?/g, '');

        // Find JSON in text
        const jsonMatch = text.match(/\{[\s\S]*\}/);
        return jsonMatch ? jsonMatch[0] : text;
    }

    getAllKeys(obj, prefix = '') {
        const keys = [];
        for (const key in obj) {
            const fullKey = prefix ? `${prefix}.${key}` : key;
            keys.push(fullKey);
            if (typeof obj[key] === 'object' && obj[key] !== null && !Array.isArray(obj[key])) {
                keys.push(...this.getAllKeys(obj[key], fullKey));
            }
        }
        return keys;
    }

    getNestedValue(obj, path) {
        return path.split('.').reduce((curr, key) => curr?.[key], obj);
    }

    setNestedValue(obj, path, value) {
        const keys = path.split('.');
        const lastKey = keys.pop();
        const target = keys.reduce((curr, key) => {
            if (!curr[key]) curr[key] = {};
            return curr[key];
        }, obj);
        target[lastKey] = value;
    }

    findMode(arr) {
        const counts = {};
        arr.forEach(val => counts[val] = (counts[val] || 0) + 1);
        return Object.keys(counts).reduce((a, b) => counts[a] > counts[b] ? a : b);
    }

    estimateCost(llm, usage) {
        // Rough estimates (adjust based on actual pricing)
        const pricing = {
            claude: { input: 0.003, output: 0.015 }, // per 1k tokens
            gpt: { input: 0.01, output: 0.03 },      // per 1k tokens
            grok: { input: 0.005, output: 0.02 }     // estimated
        };

        const rates = pricing[llm];
        const inputCost = (usage.input_tokens / 1000) * rates.input;
        const outputCost = (usage.output_tokens / 1000) * rates.output;

        return inputCost + outputCost;
    }

    sleep(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }
}

// ===== EXPORT =====
export default UnifiedLLMScraper;

// ===== USAGE EXAMPLES =====

/*
// Initialize scraper
const scraper = new UnifiedLLMScraper();

// Scrape single property
const property = await scraper.scrapeProperty(
    'https://www.realtor.com/realestateandhomes-detail/123-Main-St_Miami_FL_33101',
    'auto' // or 'claude', 'gpt', 'grok', 'hybrid'
);

// Scrape entire city
const miamiProperties = await scraper.scrapeCity('Miami', 'FL', {
    maxProperties: 100,
    minPrice: 300000,
    maxPrice: 1000000,
    propertyTypes: ['single_family']
});

// Batch scrape multiple URLs
const urls = [
    'https://www.zillow.com/homedetails/...',
    'https://www.realtor.com/property/...',
    // ... more URLs
];

const { results, errors } = await scraper.scrapeMultipleProperties(urls, {
    batchSize: 5,
    useHybrid: true // Use all 3 LLMs for critical data
});

// Get Walk Score via LLM
const walkScores = await scraper.getWalkScoreViaLLM('123 Main St, Miami, FL 33101');

// Get Crime Data via LLM
const crimeData = await scraper.getCrimeDataViaLLM('123 Main St, Miami, FL 33101');

// Check costs
console.log(`Total spent: $${scraper.totalCost.toFixed(4)}`);
console.log(`Claude calls: ${scraper.claudeCount}`);
console.log(`GPT calls: ${scraper.gptCount}`);
console.log(`Grok calls: ${scraper.grokCount}`);
*/
```

---

## üí∞ COST ANALYSIS: LLM vs Traditional Scraping

### **Per Property Cost (Estimated):**

| Method | Cost | Notes |
|--------|------|-------|
| **Claude Only** | $0.02-0.05 | Most accurate, best structured data |
| **GPT Only** | $0.03-0.08 | Good for images, slightly pricier |
| **Grok Only** | $0.01-0.04 | Fastest, best for real-time data |
| **Hybrid (All 3)** | $0.06-0.15 | Ultimate accuracy, cross-validated |
| **Traditional Scraping** | $0.00-0.01 | Free but fragile, high maintenance |

### **Scraping 1,000 Florida Properties:**

| Scenario | Claude | GPT | Grok | Hybrid | Total Cost |
|----------|--------|-----|------|--------|------------|
| **Light** (Claude only) | 1,000 | 0 | 0 | 0 | **$20-50** |
| **Balanced** (Auto-select) | 600 | 300 | 100 | 0 | **$25-60** |
| **Premium** (Hybrid critical) | 300 | 300 | 300 | 100 | **$50-120** |

**üí° RECOMMENDATION:** Use auto-select (balanced) for 95% of properties, hybrid for high-value listings ($1M+)

---

## üöÄ DEPLOYMENT STRATEGY

### **Phase 1: Proof of Concept (1 day)**
```javascript
// Test single property with all 3 LLMs
const scraper = new UnifiedLLMScraper();

const testURL = 'https://www.zillow.com/homedetails/123-Ocean-Dr-Miami-FL-33139';

console.log('Testing Claude...');
const claudeResult = await scraper.scrapeWithClaude(testURL);
console.log(claudeResult);

console.log('Testing GPT...');
const gptResult = await scraper.scrapeWithGPT(testURL);
console.log(gptResult);

console.log('Testing Grok...');
const grokResult = await scraper.scrapeWithGrok(testURL);
console.log(grokResult);

console.log('Testing Hybrid...');
const hybridResult = await scraper.scrapeWithHybrid(testURL);
console.log(hybridResult);

// Compare accuracy and cost
```

### **Phase 2: City Scraping (2-3 days)**
```javascript
// Scrape Miami (test market)
const miami = await scraper.scrapeCity('Miami', 'FL', {
    maxProperties: 50,  // Start small
    minPrice: 200000,
    maxPrice: 5000000
});

console.log(`Scraped ${miami.scraped} properties`);
console.log(`Cost: $${scraper.totalCost.toFixed(2)}`);
console.log(`Success rate: ${(miami.scraped / miami.totalFound * 100).toFixed(1)}%`);
```

### **Phase 3: State-Wide (1-2 weeks)**
```javascript
// Scrape all major Florida cities
const FLORIDA_CITIES = [
    'Miami', 'Tampa', 'Orlando', 'Jacksonville',
    'Fort Lauderdale', 'St Petersburg', 'Hialeah',
    'Port St Lucie', 'Cape Coral', 'Tallahassee'
    // ... 50+ cities
];

for (const city of FLORIDA_CITIES) {
    const result = await scraper.scrapeCity(city, 'FL', {
        maxProperties: 100,
        minPrice: 100000,
        maxPrice: 10000000
    });

    console.log(`${city}: ${result.scraped} properties, $${scraper.totalCost.toFixed(2)}`);

    // Daily rate limiting pause
    await scraper.sleep(3600000); // 1 hour between cities
}
```

---

## üéØ ADVANTAGES SPECIFIC TO YOUR SETUP

### **1. Walk Score - LLM Can Get It!**
‚úÖ **YES** - LLMs can visit walkscore.com and extract scores
‚úÖ No API key needed
‚úÖ Can also infer from neighborhood descriptions
‚úÖ Grok is best for this (real-time web search)

```javascript
// Example: Get Walk Score without API
const walkData = await scraper.getWalkScoreViaLLM('123 Main St, Miami, FL');
console.log(walkData);
// {
//     "walk_score": 82,
//     "transit_score": 68,
//     "bike_score": 75,
//     "description": "Very Walkable"
// }
```

### **2. Crime Data - LLM Can Get It!**
‚úÖ **YES** - LLMs can scrape NeighborhoodScout, SpotCrime, etc.
‚úÖ Can synthesize from multiple sources
‚úÖ Natural language understanding ("safe neighborhood" ‚Üí crime_rating: "low")
‚úÖ Claude is best for this (structured extraction)

```javascript
// Example: Get Crime Data without API
const crimeData = await scraper.getCrimeDataViaLLM('123 Main St, Miami, FL');
console.log(crimeData);
// {
//     "crime_index": 22,
//     "crime_rating": "low",
//     "safety_score": 88,
//     "description": "Safer than 78% of neighborhoods"
// }
```

### **3. School Ratings - LLM Can Get Them!**
‚úÖ **YES** - LLMs can extract from listing pages OR search GreatSchools
‚úÖ Most listing sites already show school ratings
‚úÖ Can look up missing schools automatically
‚úÖ GPT is best for this (web browsing)

### **4. Photos & 3D Tours - LLM Can Extract!**
‚úÖ **YES** - LLMs can find ALL photo URLs
‚úÖ Can extract 3D tour links (Matterport, Zillow 3D Home)
‚úÖ GPT-4 Vision can even describe photos
‚úÖ Can identify best photos for display

### **5. Price History - LLM Can Get It!**
‚úÖ **YES** - Visible on Zillow, Redfin, Realtor.com
‚úÖ LLMs extract entire price history timeline
‚úÖ Can infer price reductions from context
‚úÖ Claude is best for structured historical data

---

## üõ°Ô∏è ADVANTAGES OVER TRADITIONAL SCRAPING

| Feature | Traditional Scraping | LLM-First |
|---------|---------------------|-----------|
| **Maintenance** | Breaks with every site update | Self-healing, adapts automatically |
| **Coverage** | One scraper per site | Universal scraper for ALL sites |
| **Intelligence** | Dumb pattern matching | Understands context, fills gaps |
| **Legal Risk** | Aggressive scraping = ToS violations | Behaves like human browser |
| **Data Quality** | Extracts only visible fields | Infers missing data intelligently |
| **Error Handling** | Crashes on unexpected layouts | Gracefully adapts to changes |
| **Development Time** | Weeks per site | Hours for all sites |
| **Multi-Source** | Complex merge logic needed | LLM handles consensus automatically |

---

## üìä RECOMMENDED WORKFLOW

```javascript
// Daily automated workflow
async function dailyPropertyUpdate() {
    const scraper = new UnifiedLLMScraper();

    // 1. Get new listings (Grok - fast web search)
    console.log('üîç Finding new listings...');
    const newListings = await scraper.grok.complete({
        model: 'grok-2-latest',
        messages: [{
            role: 'user',
            content: 'Find all NEW Florida property listings posted in the last 24 hours. Return URLs as JSON array.'
        }],
        tools: ['web_search']
    });

    const urls = JSON.parse(scraper.extractJSON(newListings.output));

    // 2. Scrape new listings (Claude - best accuracy)
    console.log(`üì¶ Scraping ${urls.length} new properties...`);
    const { results, errors } = await scraper.scrapeMultipleProperties(urls, {
        batchSize: 10,
        preferredLLM: 'claude'
    });

    // 3. Update existing properties with price changes (Grok - fast checks)
    console.log('üí∞ Checking for price changes...');
    const existingProps = await dataManager.getAllProperties();

    for (const prop of existingProps) {
        if (prop.status.current === 'active') {
            // Quick LLM check: "Did price change for {url}?"
            const priceCheck = await scraper.grok.complete({
                model: 'grok-2-latest',
                messages: [{
                    role: 'user',
                    content: `Check if price changed for ${prop.source_url}. Return: {"changed": true/false, "new_price": number or null}`
                }]
            });

            const change = JSON.parse(scraper.extractJSON(priceCheck.output));

            if (change.changed) {
                console.log(`üí∞ Price change: ${prop.address.street} - $${prop.price.current} ‚Üí $${change.new_price}`);

                // Full re-scrape of this property
                const updated = await scraper.scrapeProperty(prop.source_url, 'claude');
                await dataManager.updateProperty(prop.property_id, updated);

                // Create alert
                await dataManager.addAlert({
                    type: 'price_change',
                    property_id: prop.property_id,
                    message: `Price reduced: ${prop.address.street}`,
                    severity: 'medium'
                });
            }
        }
    }

    console.log(`‚úÖ Daily update complete - Cost: $${scraper.totalCost.toFixed(2)}`);
}

// Run daily at 3 AM
setInterval(dailyPropertyUpdate, 86400000);
```

---

## üéâ CONCLUSION: WHY LLM-FIRST IS PERFECT FOR CLUES‚Ñ¢

1. ‚úÖ **Aligns with your AI-first philosophy** - CLUES‚Ñ¢ uses AI for scoring, why not data collection?
2. ‚úÖ **You already have the APIs** - Claude Max, GPT Pro, Grok Pro (no extra subscriptions)
3. ‚úÖ **Future-proof** - No maintenance as sites change layouts
4. ‚úÖ **Comprehensive** - LLMs find data traditional scrapers miss
5. ‚úÖ **Intelligent** - Fills missing fields, validates data, corrects errors
6. ‚úÖ **Cost-effective** - $20-100/mo for 1,000+ properties vs $500+ for MLS subscriptions
7. ‚úÖ **Faster development** - Build in days, not months
8. ‚úÖ **Better data quality** - Cross-validation with 3 LLMs
9. ‚úÖ **Legal compliance** - Behaves like human browsing
10. ‚úÖ **Scalable** - Same code works for Florida, then nationwide

---

## üöÄ NEXT STEP: BUILD IT NOW?

**I can implement the complete `UnifiedLLMScraper` class right now with:**
- ‚úÖ Claude Max integration
- ‚úÖ GPT Pro integration
- ‚úÖ Grok Pro integration (once you provide API details)
- ‚úÖ Hybrid consensus system
- ‚úÖ Walk Score extraction via LLM
- ‚úÖ Crime data extraction via LLM
- ‚úÖ School ratings extraction
- ‚úÖ Batch processing
- ‚úÖ Cost tracking
- ‚úÖ Error handling
- ‚úÖ Integration with your existing `data-manager.js`

**Want me to start building?** üéØ
